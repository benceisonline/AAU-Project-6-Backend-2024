{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Just use the Google Colab Notebook for now, it is faster"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1-HjiISktfm"
      },
      "source": [
        "LightFM Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9_HN2IkkvP8"
      },
      "source": [
        "Source: https://github.com/recommenders-team/recommenders/blob/main/examples/02_model_collaborative_filtering/lightfm_deep_dive.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDuxfQ-Whsnb"
      },
      "source": [
        "Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNZ9aEbihu-o",
        "outputId": "62856f50-de7b-4ed5-e487-c84612a76ae8"
      },
      "outputs": [],
      "source": [
        "!pip install lightfm\n",
        "!pip install recommenders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jV4K9D2hqd0"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLvLGN2zhiXr",
        "outputId": "4af6c171-9af2-4768-c578-a4f0c70a3b86"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import lightfm\n",
        "from lightfm import LightFM\n",
        "from lightfm.data import Dataset\n",
        "from lightfm import cross_validation\n",
        "from lightfm.evaluation import precision_at_k as lightfm_prec_at_k\n",
        "from lightfm.evaluation import recall_at_k as lightfm_recall_at_k\n",
        "\n",
        "from recommenders.evaluation.python_evaluation import precision_at_k, recall_at_k\n",
        "from recommenders.utils.timer import Timer\n",
        "from recommenders.datasets import movielens\n",
        "from recommenders.models.lightfm.lightfm_utils import (\n",
        "    track_model_metrics,\n",
        "    prepare_test_df,\n",
        "    prepare_all_predictions,\n",
        "    compare_metric,\n",
        "    similar_users,\n",
        "    similar_items,\n",
        ")\n",
        "from recommenders.utils.notebook_utils import store_metadata\n",
        "\n",
        "print(\"System version: {}\".format(sys.version))\n",
        "print(\"LightFM version: {}\".format(lightfm.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARRcdW9zjxa6"
      },
      "source": [
        "Defining variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mqe-betdjzcn"
      },
      "outputs": [],
      "source": [
        "# Select MovieLens data size\n",
        "MOVIELENS_DATA_SIZE = '100k'\n",
        "\n",
        "# default number of recommendations\n",
        "K = 10\n",
        "# percentage of data used for testing\n",
        "TEST_PERCENTAGE = 0.25\n",
        "# model learning rate\n",
        "LEARNING_RATE = 0.25\n",
        "# no of latent factors\n",
        "NO_COMPONENTS = 20\n",
        "# no of epochs to fit model\n",
        "NO_EPOCHS = 20\n",
        "# no of threads to fit model\n",
        "NO_THREADS = 32\n",
        "# regularisation for both user and item features\n",
        "ITEM_ALPHA = 1e-6\n",
        "USER_ALPHA = 1e-6\n",
        "\n",
        "# seed for pseudonumber generations\n",
        "SEED = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RsLqhTCj3Oy"
      },
      "source": [
        "Retrieve data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "tQ6X9sOgj2n5",
        "outputId": "98db3329-d8d6-402b-8df7-df646d93043d"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"exported_data/data.csv\")\n",
        "# quick look at the data\n",
        "data.sample(5, random_state=SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUbO4aScj7v0"
      },
      "source": [
        "Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDT37bT7j_Kx"
      },
      "outputs": [],
      "source": [
        "dataset = Dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC8gV3xrkBwn",
        "outputId": "c08a19f5-9865-4938-d996-03b3e216b609"
      },
      "outputs": [],
      "source": [
        "dataset.fit(users=data['userID'],\n",
        "            items=data['itemID'])\n",
        "\n",
        "# quick check to determine the number of unique users and items in the data\n",
        "num_users, num_topics = dataset.interactions_shape()\n",
        "print(f'Num users: {num_users}, num_topics: {num_topics}.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lE6mlYPtkD6Z"
      },
      "outputs": [],
      "source": [
        "(interactions, weights) = dataset.build_interactions(data.iloc[:, 0:3].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJtmLG37kGXE"
      },
      "outputs": [],
      "source": [
        "train_interactions, test_interactions = cross_validation.random_train_test_split(\n",
        "    interactions, test_percentage=TEST_PERCENTAGE,\n",
        "    random_state=np.random.RandomState(SEED))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzZBJ1sZkIRC",
        "outputId": "5c9af320-b268-4894-d1d0-3280b515439e"
      },
      "outputs": [],
      "source": [
        "print(f\"Shape of train interactions: {train_interactions.shape}\")\n",
        "print(f\"Shape of test interactions: {test_interactions.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuISqPg1kPiz"
      },
      "source": [
        "Fit the LightFM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pG90lR6SkRS4"
      },
      "outputs": [],
      "source": [
        "model1 = LightFM(loss='warp', no_components=NO_COMPONENTS,\n",
        "                 learning_rate=LEARNING_RATE,\n",
        "                 random_state=np.random.RandomState(SEED))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-K2DdxfkTVf"
      },
      "outputs": [],
      "source": [
        "model1.fit(interactions=train_interactions,\n",
        "          epochs=NO_EPOCHS);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ed7BbWdJkjsN"
      },
      "source": [
        "Prepare model evaluation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1d0UPqRrklJK"
      },
      "outputs": [],
      "source": [
        "uids, iids, interaction_data = cross_validation._shuffle(\n",
        "    interactions.row, interactions.col, interactions.data,\n",
        "    random_state=np.random.RandomState(SEED))\n",
        "\n",
        "cutoff = int((1.0 - TEST_PERCENTAGE) * len(uids))\n",
        "test_idx = slice(cutoff, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uxAUF6ekp_M"
      },
      "outputs": [],
      "source": [
        "uid_map, ufeature_map, iid_map, ifeature_map = dataset.mapping()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNzcCAD7kyY8",
        "outputId": "3577414c-d0bc-44fb-c48c-b170dfcde8d1"
      },
      "outputs": [],
      "source": [
        "with Timer() as test_time:\n",
        "    test_df = prepare_test_df(test_idx, uids, iids, uid_map, iid_map, weights)\n",
        "print(f\"Took {test_time.interval:.1f} seconds for prepare and predict test data.\")\n",
        "time_reco1 = test_time.interval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vn9CTWqzk22Q",
        "outputId": "ef3fc506-2284-4ae7-8a6f-a34737fc6f42"
      },
      "outputs": [],
      "source": [
        "test_df.sample(5, random_state=SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LLhAdotk5PX",
        "outputId": "f187492b-5525-447a-c0de-6d0b6b46f8ec"
      },
      "outputs": [],
      "source": [
        "with Timer() as test_time:\n",
        "    all_predictions = prepare_all_predictions(data, uid_map, iid_map,\n",
        "                                              interactions=train_interactions,\n",
        "                                              model=model1,\n",
        "                                              num_threads=NO_THREADS)\n",
        "print(f\"Took {test_time.interval:.1f} seconds for prepare and predict all data.\")\n",
        "time_reco2 = test_time.interval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kuNxBmuFlqsm",
        "outputId": "9141cd1d-0d3d-4491-d202-d3ba4e0c6d76"
      },
      "outputs": [],
      "source": [
        "all_predictions.sample(5, random_state=SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa-6_RyU2gfn"
      },
      "source": [
        "Export all predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-6IYix82jO3",
        "outputId": "24d751b8-80f5-4430-882c-034a5de1acdc"
      },
      "outputs": [],
      "source": [
        "# Define the file path where you want to save the predictions\n",
        "predictions_file_path = 'model_predictions.csv'\n",
        "\n",
        "# Export all predictions to a CSV file\n",
        "all_predictions.to_csv(predictions_file_path, index=False)\n",
        "print(f\"All model predictions exported successfully to {predictions_file_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b_HLYGepp3s"
      },
      "source": [
        "Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyNuxzkKprX7",
        "outputId": "acc970bf-60b4-4cd0-8c9c-89146a0c43ad"
      },
      "outputs": [],
      "source": [
        "with Timer() as test_time:\n",
        "    eval_precision = precision_at_k(rating_true=test_df,\n",
        "                                rating_pred=all_predictions, k=K)\n",
        "    eval_recall = recall_at_k(test_df, all_predictions, k=K)\n",
        "time_reco3 = test_time.interval\n",
        "\n",
        "with Timer() as test_time:\n",
        "    eval_precision_lfm = lightfm_prec_at_k(model1, test_interactions,\n",
        "                                           train_interactions, k=K).mean()\n",
        "    eval_recall_lfm = lightfm_recall_at_k(model1, test_interactions,\n",
        "                                          train_interactions, k=K).mean()\n",
        "time_lfm = test_time.interval\n",
        "\n",
        "print(\n",
        "    \"------ Using Repo's evaluation methods ------\",\n",
        "    f\"Precision@K:\\t{eval_precision:.6f}\",\n",
        "    f\"Recall@K:\\t{eval_recall:.6f}\",\n",
        "    \"\\n------ Using LightFM evaluation methods ------\",\n",
        "    f\"Precision@K:\\t{eval_precision_lfm:.6f}\",\n",
        "    f\"Recall@K:\\t{eval_recall_lfm:.6f}\",\n",
        "    sep='\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfloSQ19unAx"
      },
      "source": [
        "Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoD10krquoU2",
        "outputId": "69427326-4ea6-4cb4-9510-5b2d9ef92e32"
      },
      "outputs": [],
      "source": [
        "def get_top_predictions_for_user(user_id, all_predictions_df, k=10):\n",
        "    user_predictions = all_predictions_df[all_predictions_df['userID'] == user_id]\n",
        "    top_predictions = user_predictions.sort_values(by='prediction', ascending=False).head(k)\n",
        "    return top_predictions\n",
        "\n",
        "# Example usage: Get top predictions for user with ID\n",
        "user_id = 626\n",
        "top_predictions_for_user = get_top_predictions_for_user(user_id, all_predictions)\n",
        "print(f\"Top {K} predictions for user {user_id}:\")\n",
        "print(top_predictions_for_user)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyZe3zudv-0U"
      },
      "source": [
        "Export model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx2xZogKwAWF",
        "outputId": "c6d3f56d-18db-43c0-f2ae-526278cf8586"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "# Define the file path where you want to save the model\n",
        "model_file_path = 'lightfm_model.pkl'\n",
        "\n",
        "# Export the model\n",
        "joblib.dump(model1, model_file_path)\n",
        "print(f\"Model exported successfully to {model_file_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfZH4dNjwIEJ"
      },
      "source": [
        "Import model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_KAQa92wJG_",
        "outputId": "9a6ea834-607b-4fc0-df4b-155a85a72c5c"
      },
      "outputs": [],
      "source": [
        "# Define the file path from where you want to load the model\n",
        "loaded_model = joblib.load(model_file_path)\n",
        "\n",
        "# Check if the loaded object is an instance of the LightFM model class\n",
        "if isinstance(loaded_model, LightFM):\n",
        "    print(\"Model loaded successfully!\")\n",
        "else:\n",
        "    print(\"Failed to load the model. Please check the file path or the model file.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vd2hpb_6xUly"
      },
      "source": [
        "Prepare predictions with imported model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VogbiVblxWzT",
        "outputId": "ad910c60-afc3-4c14-cd84-c0a42c2e3fd1"
      },
      "outputs": [],
      "source": [
        "with Timer() as test_time:\n",
        "    loaded_model_predictions = prepare_all_predictions(data, uid_map, iid_map,\n",
        "                                                       interactions=train_interactions,\n",
        "                                                       model=loaded_model,\n",
        "                                                       num_threads=NO_THREADS)\n",
        "print(f\"Took {test_time.interval:.1f} seconds for prepare and predict all data.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCmzIBg7xkXe"
      },
      "source": [
        "Output prediction for specific user with imported model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DM_XDlidxm7q",
        "outputId": "f9c29e83-b642-4f60-e5d8-d6dcf7c4f656"
      },
      "outputs": [],
      "source": [
        "user_id = 626\n",
        "top_predictions_for_user = get_top_predictions_for_user(user_id, loaded_model_predictions)\n",
        "print(f\"Top {K} predictions for user {user_id}:\")\n",
        "print(top_predictions_for_user)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
