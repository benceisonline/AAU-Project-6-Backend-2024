{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing necessary packages for the notebook by running shell commands. We recommend using a Conda virtual environment to ensure reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch_lightning in d:\\anaconda\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.2 in d:\\anaconda\\lib\\site-packages (from pytorch_lightning) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.13.0 in d:\\anaconda\\lib\\site-packages (from pytorch_lightning) (2.2.1)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in d:\\anaconda\\lib\\site-packages (from pytorch_lightning) (4.65.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in d:\\anaconda\\lib\\site-packages (from pytorch_lightning) (6.0.1)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in d:\\anaconda\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2023.10.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in d:\\anaconda\\lib\\site-packages (from pytorch_lightning) (1.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from pytorch_lightning) (23.1)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in d:\\anaconda\\lib\\site-packages (from pytorch_lightning) (4.9.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in d:\\anaconda\\lib\\site-packages (from pytorch_lightning) (0.10.1)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2.31.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in d:\\anaconda\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.9.3)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda\\lib\\site-packages (from lightning-utilities>=0.8.0->pytorch_lightning) (68.2.2)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from torch>=1.13.0->pytorch_lightning) (3.13.1)\n",
      "Requirement already satisfied: sympy in d:\\anaconda\\lib\\site-packages (from torch>=1.13.0->pytorch_lightning) (1.12)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\lib\\site-packages (from torch>=1.13.0->pytorch_lightning) (3.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from torch>=1.13.0->pytorch_lightning) (3.1.3)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm>=4.57.0->pytorch_lightning) (0.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\anaconda\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\anaconda\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\anaconda\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\anaconda\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\anaconda\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.9.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\lib\\site-packages (from jinja2->torch>=1.13.0->pytorch_lightning) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda\\lib\\site-packages (from sympy->torch>=1.13.0->pytorch_lightning) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchmetrics in d:\\anaconda\\lib\\site-packages (1.3.1)\n",
      "Requirement already satisfied: numpy>1.20.0 in d:\\anaconda\\lib\\site-packages (from torchmetrics) (1.26.4)\n",
      "Requirement already satisfied: packaging>17.1 in d:\\anaconda\\lib\\site-packages (from torchmetrics) (23.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in d:\\anaconda\\lib\\site-packages (from torchmetrics) (2.2.1)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in d:\\anaconda\\lib\\site-packages (from torchmetrics) (0.10.1)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (68.2.2)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n",
      "Requirement already satisfied: sympy in d:\\anaconda\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\lib\\site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda\\lib\\site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tensorboard in d:\\anaconda\\lib\\site-packages (2.16.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in d:\\anaconda\\lib\\site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in d:\\anaconda\\lib\\site-packages (from tensorboard) (1.62.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\anaconda\\lib\\site-packages (from tensorboard) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in d:\\anaconda\\lib\\site-packages (from tensorboard) (1.26.4)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in d:\\anaconda\\lib\\site-packages (from tensorboard) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in d:\\anaconda\\lib\\site-packages (from tensorboard) (68.2.2)\n",
      "Requirement already satisfied: six>1.9 in d:\\anaconda\\lib\\site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\anaconda\\lib\\site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\anaconda\\lib\\site-packages (from tensorboard) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\anaconda\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in d:\\anaconda\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in d:\\anaconda\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\anaconda\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nbconvert in d:\\anaconda\\lib\\site-packages (7.10.0)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda\\lib\\site-packages (from nbconvert) (4.12.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in d:\\anaconda\\lib\\site-packages (from nbconvert) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in d:\\anaconda\\lib\\site-packages (from nbconvert) (0.7.1)\n",
      "Requirement already satisfied: jinja2>=3.0 in d:\\anaconda\\lib\\site-packages (from nbconvert) (3.1.3)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in d:\\anaconda\\lib\\site-packages (from nbconvert) (5.5.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in d:\\anaconda\\lib\\site-packages (from nbconvert) (0.1.2)\n",
      "Requirement already satisfied: markupsafe>=2.0 in d:\\anaconda\\lib\\site-packages (from nbconvert) (2.1.3)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in d:\\anaconda\\lib\\site-packages (from nbconvert) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in d:\\anaconda\\lib\\site-packages (from nbconvert) (0.8.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in d:\\anaconda\\lib\\site-packages (from nbconvert) (5.9.2)\n",
      "Requirement already satisfied: packaging in d:\\anaconda\\lib\\site-packages (from nbconvert) (23.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in d:\\anaconda\\lib\\site-packages (from nbconvert) (1.5.0)\n",
      "Requirement already satisfied: pygments>=2.4.1 in d:\\anaconda\\lib\\site-packages (from nbconvert) (2.15.1)\n",
      "Requirement already satisfied: tinycss2 in d:\\anaconda\\lib\\site-packages (from nbconvert) (1.2.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in d:\\anaconda\\lib\\site-packages (from nbconvert) (5.7.1)\n",
      "Requirement already satisfied: six>=1.9.0 in d:\\anaconda\\lib\\site-packages (from bleach!=5.0.0->nbconvert) (1.16.0)\n",
      "Requirement already satisfied: webencodings in d:\\anaconda\\lib\\site-packages (from bleach!=5.0.0->nbconvert) (0.5.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in d:\\anaconda\\lib\\site-packages (from jupyter-core>=4.7->nbconvert) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in d:\\anaconda\\lib\\site-packages (from jupyter-core>=4.7->nbconvert) (305.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in d:\\anaconda\\lib\\site-packages (from nbclient>=0.5.0->nbconvert) (8.6.0)\n",
      "Requirement already satisfied: fastjsonschema in d:\\anaconda\\lib\\site-packages (from nbformat>=5.7->nbconvert) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in d:\\anaconda\\lib\\site-packages (from nbformat>=5.7->nbconvert) (4.19.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\lib\\site-packages (from beautifulsoup4->nbconvert) (2.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in d:\\anaconda\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\anaconda\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in d:\\anaconda\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in d:\\anaconda\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.10.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (2.8.2)\n",
      "Requirement already satisfied: pyzmq>=23.0 in d:\\anaconda\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.2 in d:\\anaconda\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (6.3.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pytorch_lightning\n",
    "%pip install torchmetrics\n",
    "%pip install --upgrade tensorboard\n",
    "%pip install pandas\n",
    "%pip install nbconvert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries for data manipulation, neural network building, and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import os\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import for TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part sets up TensorBoard logger, which is used for visualization and monitoring of the model's training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"my_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we load and preprocess the data. It includes loading data from Parquet files, joining tables, generating binary labels, building indexes for items and users, and splitting the data into train and validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, behaviour data is loaded. We concatinate training and validation sets, so we can choose our own ratios later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>impression_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>impression_time</th>\n",
       "      <th>read_time</th>\n",
       "      <th>scroll_percentage</th>\n",
       "      <th>device_type</th>\n",
       "      <th>article_ids_inview</th>\n",
       "      <th>article_ids_clicked</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_sso_user</th>\n",
       "      <th>gender</th>\n",
       "      <th>postcode</th>\n",
       "      <th>age</th>\n",
       "      <th>is_subscriber</th>\n",
       "      <th>session_id</th>\n",
       "      <th>next_read_time</th>\n",
       "      <th>next_scroll_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-24 07:47:53</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>[9778623, 9778682, 9778669, 9778657, 9778736, ...</td>\n",
       "      <td>[9778657]</td>\n",
       "      <td>139836</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>759</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-24 07:33:25</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>[9778718, 9778728, 9778745, 9778669, 9778657, ...</td>\n",
       "      <td>[9778623]</td>\n",
       "      <td>143471</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1240</td>\n",
       "      <td>287.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153068</td>\n",
       "      <td>9778682.0</td>\n",
       "      <td>2023-05-24 07:09:04</td>\n",
       "      <td>78.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[9778657, 9778669, 9772866, 9776259, 9756397, ...</td>\n",
       "      <td>[9778669]</td>\n",
       "      <td>151570</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1976</td>\n",
       "      <td>45.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153070</td>\n",
       "      <td>9777492.0</td>\n",
       "      <td>2023-05-24 07:13:14</td>\n",
       "      <td>26.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[9020783, 9778444, 9525589, 7213923, 9777397, ...</td>\n",
       "      <td>[9778628]</td>\n",
       "      <td>151570</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1976</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153071</td>\n",
       "      <td>9778623.0</td>\n",
       "      <td>2023-05-24 07:11:08</td>\n",
       "      <td>125.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[9777492, 9774568, 9565836, 9335113, 9771223, ...</td>\n",
       "      <td>[9777492]</td>\n",
       "      <td>151570</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1976</td>\n",
       "      <td>26.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   impression_id  article_id     impression_time  read_time  \\\n",
       "0         149474         NaN 2023-05-24 07:47:53       13.0   \n",
       "1         150528         NaN 2023-05-24 07:33:25       25.0   \n",
       "2         153068   9778682.0 2023-05-24 07:09:04       78.0   \n",
       "3         153070   9777492.0 2023-05-24 07:13:14       26.0   \n",
       "4         153071   9778623.0 2023-05-24 07:11:08      125.0   \n",
       "\n",
       "   scroll_percentage  device_type  \\\n",
       "0                NaN            2   \n",
       "1                NaN            2   \n",
       "2              100.0            1   \n",
       "3              100.0            1   \n",
       "4              100.0            1   \n",
       "\n",
       "                                  article_ids_inview article_ids_clicked  \\\n",
       "0  [9778623, 9778682, 9778669, 9778657, 9778736, ...           [9778657]   \n",
       "1  [9778718, 9778728, 9778745, 9778669, 9778657, ...           [9778623]   \n",
       "2  [9778657, 9778669, 9772866, 9776259, 9756397, ...           [9778669]   \n",
       "3  [9020783, 9778444, 9525589, 7213923, 9777397, ...           [9778628]   \n",
       "4  [9777492, 9774568, 9565836, 9335113, 9771223, ...           [9777492]   \n",
       "\n",
       "   user_id  is_sso_user  gender  postcode  age  is_subscriber  session_id  \\\n",
       "0   139836        False     NaN       NaN  NaN          False         759   \n",
       "1   143471        False     NaN       NaN  NaN          False        1240   \n",
       "2   151570        False     NaN       NaN  NaN          False        1976   \n",
       "3   151570        False     NaN       NaN  NaN          False        1976   \n",
       "4   151570        False     NaN       NaN  NaN          False        1976   \n",
       "\n",
       "   next_read_time  next_scroll_percentage  \n",
       "0             7.0                    22.0  \n",
       "1           287.0                   100.0  \n",
       "2            45.0                   100.0  \n",
       "3             4.0                    18.0  \n",
       "4            26.0                   100.0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load EBNeRD behaviors dataset for both train and validation\n",
    "train_behaviour = pd.read_parquet(\"./ebnerd_small/train/behaviors.parquet\")\n",
    "valid_behaviour = pd.read_parquet(\"./ebnerd_small/validation/behaviors.parquet\")\n",
    "behaviors = pd.concat([train_behaviour, valid_behaviour], ignore_index=True)\n",
    "\n",
    "behaviors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "History data is loaded. We concatinate training and validation sets, so we can choose our own ratios later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>impression_time_fixed</th>\n",
       "      <th>scroll_percentage_fixed</th>\n",
       "      <th>article_id_fixed</th>\n",
       "      <th>read_time_fixed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13538</td>\n",
       "      <td>[2023-04-27T10:17:43.000000, 2023-04-27T10:18:...</td>\n",
       "      <td>[100.0, 35.0, 100.0, 24.0, 100.0, 23.0, 100.0,...</td>\n",
       "      <td>[9738663, 9738569, 9738663, 9738490, 9738663, ...</td>\n",
       "      <td>[17.0, 12.0, 4.0, 5.0, 4.0, 9.0, 5.0, 46.0, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14241</td>\n",
       "      <td>[2023-04-27T09:40:18.000000, 2023-04-27T09:40:...</td>\n",
       "      <td>[100.0, 46.0, 100.0, 70.0, 100.0, 100.0, 100.0...</td>\n",
       "      <td>[9738557, 9738528, 9738533, 9738684, 9739035, ...</td>\n",
       "      <td>[8.0, 9.0, 28.0, 17.0, 91.0, 21.0, 14.0, 27.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20396</td>\n",
       "      <td>[2023-04-27T12:30:44.000000, 2023-04-27T12:31:...</td>\n",
       "      <td>[100.0, 59.0, nan, nan, 100.0, 100.0, nan, nan...</td>\n",
       "      <td>[9738760, 9738355, 9738355, 9739864, 9741788, ...</td>\n",
       "      <td>[49.0, 34.0, 0.0, 60.0, 180.0, 49.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34912</td>\n",
       "      <td>[2023-04-29T07:12:49.000000, 2023-04-29T13:01:...</td>\n",
       "      <td>[100.0, 35.0, 44.0, 31.0, 100.0, 100.0, 100.0,...</td>\n",
       "      <td>[9741802, 9741804, 9741803, 9740087, 9742039, ...</td>\n",
       "      <td>[153.0, 7.0, 5.0, 6.0, 44.0, 44.0, 108.0, 10.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37953</td>\n",
       "      <td>[2023-04-27T19:17:10.000000, 2023-04-27T19:17:...</td>\n",
       "      <td>[14.0, 28.0, 29.0, nan, 36.0, 33.0, 50.0, 100....</td>\n",
       "      <td>[9739205, 9739202, 9737084, 9739274, 9739358, ...</td>\n",
       "      <td>[4.0, 16.0, 4.0, 0.0, 5.0, 5.0, 25.0, 48.0, 6....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                              impression_time_fixed  \\\n",
       "0    13538  [2023-04-27T10:17:43.000000, 2023-04-27T10:18:...   \n",
       "1    14241  [2023-04-27T09:40:18.000000, 2023-04-27T09:40:...   \n",
       "2    20396  [2023-04-27T12:30:44.000000, 2023-04-27T12:31:...   \n",
       "3    34912  [2023-04-29T07:12:49.000000, 2023-04-29T13:01:...   \n",
       "4    37953  [2023-04-27T19:17:10.000000, 2023-04-27T19:17:...   \n",
       "\n",
       "                             scroll_percentage_fixed  \\\n",
       "0  [100.0, 35.0, 100.0, 24.0, 100.0, 23.0, 100.0,...   \n",
       "1  [100.0, 46.0, 100.0, 70.0, 100.0, 100.0, 100.0...   \n",
       "2  [100.0, 59.0, nan, nan, 100.0, 100.0, nan, nan...   \n",
       "3  [100.0, 35.0, 44.0, 31.0, 100.0, 100.0, 100.0,...   \n",
       "4  [14.0, 28.0, 29.0, nan, 36.0, 33.0, 50.0, 100....   \n",
       "\n",
       "                                    article_id_fixed  \\\n",
       "0  [9738663, 9738569, 9738663, 9738490, 9738663, ...   \n",
       "1  [9738557, 9738528, 9738533, 9738684, 9739035, ...   \n",
       "2  [9738760, 9738355, 9738355, 9739864, 9741788, ...   \n",
       "3  [9741802, 9741804, 9741803, 9740087, 9742039, ...   \n",
       "4  [9739205, 9739202, 9737084, 9739274, 9739358, ...   \n",
       "\n",
       "                                     read_time_fixed  \n",
       "0  [17.0, 12.0, 4.0, 5.0, 4.0, 9.0, 5.0, 46.0, 11...  \n",
       "1  [8.0, 9.0, 28.0, 17.0, 91.0, 21.0, 14.0, 27.0,...  \n",
       "2  [49.0, 34.0, 0.0, 60.0, 180.0, 49.0, 0.0, 0.0,...  \n",
       "3  [153.0, 7.0, 5.0, 6.0, 44.0, 44.0, 108.0, 10.0...  \n",
       "4  [4.0, 16.0, 4.0, 0.0, 5.0, 5.0, 25.0, 48.0, 6....  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load EBNeRD history dataset for both train and validation\n",
    "train_history = pd.read_parquet(\"./ebnerd_small/train/history.parquet\")\n",
    "valid_history = pd.read_parquet(\"./ebnerd_small/validation/history.parquet\")\n",
    "history = pd.concat([train_history, valid_history], ignore_index=True)\n",
    "\n",
    "history.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "News data is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>last_modified_time</th>\n",
       "      <th>premium</th>\n",
       "      <th>body</th>\n",
       "      <th>published_time</th>\n",
       "      <th>image_ids</th>\n",
       "      <th>article_type</th>\n",
       "      <th>url</th>\n",
       "      <th>...</th>\n",
       "      <th>entity_groups</th>\n",
       "      <th>topics</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>category_str</th>\n",
       "      <th>total_inviews</th>\n",
       "      <th>total_pageviews</th>\n",
       "      <th>total_read_time</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3001353</td>\n",
       "      <td>Natascha var ikke den første</td>\n",
       "      <td>Politiet frygter nu, at Nataschas bortfører ha...</td>\n",
       "      <td>2023-06-29 06:20:33</td>\n",
       "      <td>False</td>\n",
       "      <td>Sagen om den østriske Natascha og hendes bortf...</td>\n",
       "      <td>2006-08-31 08:06:45</td>\n",
       "      <td>[3150850]</td>\n",
       "      <td>article_default</td>\n",
       "      <td>https://ekstrabladet.dk/krimi/article3001353.ece</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Kriminalitet, Personfarlig kriminalitet]</td>\n",
       "      <td>140</td>\n",
       "      <td>[]</td>\n",
       "      <td>krimi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9955</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3003065</td>\n",
       "      <td>Kun Star Wars tjente mere</td>\n",
       "      <td>Biografgængerne strømmer ind for at se 'Da Vin...</td>\n",
       "      <td>2023-06-29 06:20:35</td>\n",
       "      <td>False</td>\n",
       "      <td>Vatikanet har opfordret til at boykotte filmen...</td>\n",
       "      <td>2006-05-21 16:57:00</td>\n",
       "      <td>[3006712]</td>\n",
       "      <td>article_default</td>\n",
       "      <td>https://ekstrabladet.dk/underholdning/filmogtv...</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Underholdning, Film og tv, Økonomi]</td>\n",
       "      <td>414</td>\n",
       "      <td>[433, 434]</td>\n",
       "      <td>underholdning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8460</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3012771</td>\n",
       "      <td>Morten Bruun fyret i SønderjyskE</td>\n",
       "      <td>FODBOLD: Morten Bruun fyret med øjeblikkelig v...</td>\n",
       "      <td>2023-06-29 06:20:39</td>\n",
       "      <td>False</td>\n",
       "      <td>Kemien mellem spillerne i Superligaklubben Søn...</td>\n",
       "      <td>2006-05-01 14:28:40</td>\n",
       "      <td>[3177953]</td>\n",
       "      <td>article_default</td>\n",
       "      <td>https://ekstrabladet.dk/sport/fodbold/dansk_fo...</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Erhverv, Kendt, Sport, Fodbold, Ansættelsesfo...</td>\n",
       "      <td>142</td>\n",
       "      <td>[196, 199]</td>\n",
       "      <td>sport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8241</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3023463</td>\n",
       "      <td>Luderne flytter på landet</td>\n",
       "      <td>I landets tyndest befolkede områder skyder bor...</td>\n",
       "      <td>2023-06-29 06:20:43</td>\n",
       "      <td>False</td>\n",
       "      <td>Det frække erhverv rykker på landet. I den tyn...</td>\n",
       "      <td>2007-03-24 08:27:59</td>\n",
       "      <td>[3184029]</td>\n",
       "      <td>article_default</td>\n",
       "      <td>https://ekstrabladet.dk/nyheder/samfund/articl...</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Livsstil, Erotik]</td>\n",
       "      <td>118</td>\n",
       "      <td>[133]</td>\n",
       "      <td>nyheder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7053</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032577</td>\n",
       "      <td>Cybersex: Hvornår er man utro?</td>\n",
       "      <td>En flirtende sms til den flotte fyr i regnskab...</td>\n",
       "      <td>2023-06-29 06:20:46</td>\n",
       "      <td>False</td>\n",
       "      <td>De fleste af os mener, at et tungekys er utros...</td>\n",
       "      <td>2007-01-18 10:30:37</td>\n",
       "      <td>[3030463]</td>\n",
       "      <td>article_default</td>\n",
       "      <td>https://ekstrabladet.dk/sex_og_samliv/article3...</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Livsstil, Partnerskab]</td>\n",
       "      <td>565</td>\n",
       "      <td>[]</td>\n",
       "      <td>sex_og_samliv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9307</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                             title  \\\n",
       "0     3001353      Natascha var ikke den første   \n",
       "1     3003065         Kun Star Wars tjente mere   \n",
       "2     3012771  Morten Bruun fyret i SønderjyskE   \n",
       "3     3023463         Luderne flytter på landet   \n",
       "4     3032577    Cybersex: Hvornår er man utro?   \n",
       "\n",
       "                                            subtitle  last_modified_time  \\\n",
       "0  Politiet frygter nu, at Nataschas bortfører ha... 2023-06-29 06:20:33   \n",
       "1  Biografgængerne strømmer ind for at se 'Da Vin... 2023-06-29 06:20:35   \n",
       "2  FODBOLD: Morten Bruun fyret med øjeblikkelig v... 2023-06-29 06:20:39   \n",
       "3  I landets tyndest befolkede områder skyder bor... 2023-06-29 06:20:43   \n",
       "4  En flirtende sms til den flotte fyr i regnskab... 2023-06-29 06:20:46   \n",
       "\n",
       "   premium                                               body  \\\n",
       "0    False  Sagen om den østriske Natascha og hendes bortf...   \n",
       "1    False  Vatikanet har opfordret til at boykotte filmen...   \n",
       "2    False  Kemien mellem spillerne i Superligaklubben Søn...   \n",
       "3    False  Det frække erhverv rykker på landet. I den tyn...   \n",
       "4    False  De fleste af os mener, at et tungekys er utros...   \n",
       "\n",
       "       published_time  image_ids     article_type  \\\n",
       "0 2006-08-31 08:06:45  [3150850]  article_default   \n",
       "1 2006-05-21 16:57:00  [3006712]  article_default   \n",
       "2 2006-05-01 14:28:40  [3177953]  article_default   \n",
       "3 2007-03-24 08:27:59  [3184029]  article_default   \n",
       "4 2007-01-18 10:30:37  [3030463]  article_default   \n",
       "\n",
       "                                                 url  ... entity_groups  \\\n",
       "0   https://ekstrabladet.dk/krimi/article3001353.ece  ...            []   \n",
       "1  https://ekstrabladet.dk/underholdning/filmogtv...  ...            []   \n",
       "2  https://ekstrabladet.dk/sport/fodbold/dansk_fo...  ...            []   \n",
       "3  https://ekstrabladet.dk/nyheder/samfund/articl...  ...            []   \n",
       "4  https://ekstrabladet.dk/sex_og_samliv/article3...  ...            []   \n",
       "\n",
       "                                              topics category  subcategory  \\\n",
       "0          [Kriminalitet, Personfarlig kriminalitet]      140           []   \n",
       "1               [Underholdning, Film og tv, Økonomi]      414   [433, 434]   \n",
       "2  [Erhverv, Kendt, Sport, Fodbold, Ansættelsesfo...      142   [196, 199]   \n",
       "3                                 [Livsstil, Erotik]      118        [133]   \n",
       "4                            [Livsstil, Partnerskab]      565           []   \n",
       "\n",
       "    category_str total_inviews  total_pageviews  total_read_time  \\\n",
       "0          krimi           NaN              NaN              NaN   \n",
       "1  underholdning           NaN              NaN              NaN   \n",
       "2          sport           NaN              NaN              NaN   \n",
       "3        nyheder           NaN              NaN              NaN   \n",
       "4  sex_og_samliv           NaN              NaN              NaN   \n",
       "\n",
       "   sentiment_score  sentiment_label  \n",
       "0           0.9955         Negative  \n",
       "1           0.8460         Positive  \n",
       "2           0.8241         Negative  \n",
       "3           0.7053          Neutral  \n",
       "4           0.9307          Neutral  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load EBNeRD news dataset\n",
    "news = pd.read_parquet(\"./ebnerd_small/articles.parquet\")\n",
    "\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join history and behaviour tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not entirely sure if it is good practice, but we join the history and behaviour tables, so we have all our data in one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>impression_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>impression_time</th>\n",
       "      <th>read_time</th>\n",
       "      <th>scroll_percentage</th>\n",
       "      <th>device_type</th>\n",
       "      <th>article_ids_inview</th>\n",
       "      <th>article_ids_clicked</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_sso_user</th>\n",
       "      <th>...</th>\n",
       "      <th>postcode</th>\n",
       "      <th>age</th>\n",
       "      <th>is_subscriber</th>\n",
       "      <th>session_id</th>\n",
       "      <th>next_read_time</th>\n",
       "      <th>next_scroll_percentage</th>\n",
       "      <th>impression_time_fixed</th>\n",
       "      <th>scroll_percentage_fixed</th>\n",
       "      <th>article_id_fixed</th>\n",
       "      <th>read_time_fixed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-24 07:47:53</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>[9778623, 9778682, 9778669, 9778657, 9778736, ...</td>\n",
       "      <td>[9778657]</td>\n",
       "      <td>139836</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>759</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>[2023-05-03T19:04:15.000000, 2023-05-03T19:05:...</td>\n",
       "      <td>[100.0, 89.0, 27.0, 33.0, 100.0, 75.0, 39.0, 2...</td>\n",
       "      <td>[9745590, 9748574, 9748432, 9748080, 9750687, ...</td>\n",
       "      <td>[60.0, 11.0, 1.0, 15.0, 37.0, 15.0, 4.0, 8.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-24 07:33:25</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>[9778718, 9778728, 9778745, 9778669, 9778657, ...</td>\n",
       "      <td>[9778623]</td>\n",
       "      <td>143471</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1240</td>\n",
       "      <td>287.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[2023-04-27T08:05:09.000000, 2023-04-27T10:05:...</td>\n",
       "      <td>[21.0, 100.0, 34.0, 85.0, 92.0, 75.0, 52.0, 66...</td>\n",
       "      <td>[9737881, 9738659, 9738569, 9738490, 9738528, ...</td>\n",
       "      <td>[7.0, 24.0, 28.0, 65.0, 16.0, 41.0, 59.0, 24.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-24 07:33:25</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>[9778718, 9778728, 9778745, 9778669, 9778657, ...</td>\n",
       "      <td>[9778623]</td>\n",
       "      <td>143471</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1240</td>\n",
       "      <td>287.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[2023-05-04T07:10:24.000000, 2023-05-04T07:10:...</td>\n",
       "      <td>[77.0, 80.0, 28.0, 11.0, 94.0, 54.0, 74.0, 30....</td>\n",
       "      <td>[9748977, 9748976, 9747490, 9745484, 9747959, ...</td>\n",
       "      <td>[3.0, 29.0, 2.0, 3.0, 16.0, 30.0, 4.0, 3.0, 4....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153068</td>\n",
       "      <td>9778682.0</td>\n",
       "      <td>2023-05-24 07:09:04</td>\n",
       "      <td>78.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[9778657, 9778669, 9772866, 9776259, 9756397, ...</td>\n",
       "      <td>[9778669]</td>\n",
       "      <td>151570</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1976</td>\n",
       "      <td>45.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[2023-04-27T14:07:16.000000, 2023-04-27T14:08:...</td>\n",
       "      <td>[100.0, nan, 100.0, 14.0, 100.0, 100.0, 100.0,...</td>\n",
       "      <td>[9738303, 9738993, 9738303, 9738902, 9738303, ...</td>\n",
       "      <td>[59.0, 1.0, 2.0, 8.0, 4.0, 28.0, 51.0, 7.0, 7....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153068</td>\n",
       "      <td>9778682.0</td>\n",
       "      <td>2023-05-24 07:09:04</td>\n",
       "      <td>78.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[9778657, 9778669, 9772866, 9776259, 9756397, ...</td>\n",
       "      <td>[9778669]</td>\n",
       "      <td>151570</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1976</td>\n",
       "      <td>45.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[2023-05-04T20:50:44.000000, 2023-05-04T20:51:...</td>\n",
       "      <td>[100.0, nan, 100.0, 100.0, 100.0, 18.0, 100.0,...</td>\n",
       "      <td>[9750389, 9749756, 9750389, 9750318, 9749582, ...</td>\n",
       "      <td>[27.0, 8.0, 10.0, 24.0, 13.0, 7.0, 5.0, 34.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   impression_id  article_id     impression_time  read_time  \\\n",
       "0         149474         NaN 2023-05-24 07:47:53       13.0   \n",
       "1         150528         NaN 2023-05-24 07:33:25       25.0   \n",
       "2         150528         NaN 2023-05-24 07:33:25       25.0   \n",
       "3         153068   9778682.0 2023-05-24 07:09:04       78.0   \n",
       "4         153068   9778682.0 2023-05-24 07:09:04       78.0   \n",
       "\n",
       "   scroll_percentage  device_type  \\\n",
       "0                NaN            2   \n",
       "1                NaN            2   \n",
       "2                NaN            2   \n",
       "3              100.0            1   \n",
       "4              100.0            1   \n",
       "\n",
       "                                  article_ids_inview article_ids_clicked  \\\n",
       "0  [9778623, 9778682, 9778669, 9778657, 9778736, ...           [9778657]   \n",
       "1  [9778718, 9778728, 9778745, 9778669, 9778657, ...           [9778623]   \n",
       "2  [9778718, 9778728, 9778745, 9778669, 9778657, ...           [9778623]   \n",
       "3  [9778657, 9778669, 9772866, 9776259, 9756397, ...           [9778669]   \n",
       "4  [9778657, 9778669, 9772866, 9776259, 9756397, ...           [9778669]   \n",
       "\n",
       "   user_id  is_sso_user  ...  postcode  age  is_subscriber  session_id  \\\n",
       "0   139836        False  ...       NaN  NaN          False         759   \n",
       "1   143471        False  ...       NaN  NaN          False        1240   \n",
       "2   143471        False  ...       NaN  NaN          False        1240   \n",
       "3   151570        False  ...       NaN  NaN          False        1976   \n",
       "4   151570        False  ...       NaN  NaN          False        1976   \n",
       "\n",
       "   next_read_time  next_scroll_percentage  \\\n",
       "0             7.0                    22.0   \n",
       "1           287.0                   100.0   \n",
       "2           287.0                   100.0   \n",
       "3            45.0                   100.0   \n",
       "4            45.0                   100.0   \n",
       "\n",
       "                               impression_time_fixed  \\\n",
       "0  [2023-05-03T19:04:15.000000, 2023-05-03T19:05:...   \n",
       "1  [2023-04-27T08:05:09.000000, 2023-04-27T10:05:...   \n",
       "2  [2023-05-04T07:10:24.000000, 2023-05-04T07:10:...   \n",
       "3  [2023-04-27T14:07:16.000000, 2023-04-27T14:08:...   \n",
       "4  [2023-05-04T20:50:44.000000, 2023-05-04T20:51:...   \n",
       "\n",
       "                             scroll_percentage_fixed  \\\n",
       "0  [100.0, 89.0, 27.0, 33.0, 100.0, 75.0, 39.0, 2...   \n",
       "1  [21.0, 100.0, 34.0, 85.0, 92.0, 75.0, 52.0, 66...   \n",
       "2  [77.0, 80.0, 28.0, 11.0, 94.0, 54.0, 74.0, 30....   \n",
       "3  [100.0, nan, 100.0, 14.0, 100.0, 100.0, 100.0,...   \n",
       "4  [100.0, nan, 100.0, 100.0, 100.0, 18.0, 100.0,...   \n",
       "\n",
       "                                    article_id_fixed  \\\n",
       "0  [9745590, 9748574, 9748432, 9748080, 9750687, ...   \n",
       "1  [9737881, 9738659, 9738569, 9738490, 9738528, ...   \n",
       "2  [9748977, 9748976, 9747490, 9745484, 9747959, ...   \n",
       "3  [9738303, 9738993, 9738303, 9738902, 9738303, ...   \n",
       "4  [9750389, 9749756, 9750389, 9750318, 9749582, ...   \n",
       "\n",
       "                                     read_time_fixed  \n",
       "0  [60.0, 11.0, 1.0, 15.0, 37.0, 15.0, 4.0, 8.0, ...  \n",
       "1  [7.0, 24.0, 28.0, 65.0, 16.0, 41.0, 59.0, 24.0...  \n",
       "2  [3.0, 29.0, 2.0, 3.0, 16.0, 30.0, 4.0, 3.0, 4....  \n",
       "3  [59.0, 1.0, 2.0, 8.0, 4.0, 28.0, 51.0, 7.0, 7....  \n",
       "4  [27.0, 8.0, 10.0, 24.0, 13.0, 7.0, 5.0, 34.0, ...  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Left join on 'user_id'\n",
    "behaviour_history_merged= pd.merge(behaviors, history, on='user_id', how='left')\n",
    "\n",
    "# Display the merged data\n",
    "behaviour_history_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every entry in history has entries article_id_fixed. With the code below, we confirm that when joining the tables, every single behaviour entry gets the corresponding user information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'article_id_fixed' column does not contain null values in any row.\n"
     ]
    }
   ],
   "source": [
    "# Check if every row has successfully been merged with the correct user information\n",
    "article_id_fixed_null = behaviour_history_merged['article_id_fixed'].isnull().any()\n",
    "\n",
    "if article_id_fixed_null:\n",
    "    print(\"The 'article_id_fixed' column contains null values in some rows.\")\n",
    "else:\n",
    "    print(\"The 'article_id_fixed' column does not contain null values in any row.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Binary Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating binary labels enables us to tackle the binary classification problem. Note that this operation could be optimised. We generate binary labels by going through articles that were shown to the user, and checking which article was clicked. The generated column is appended to the dataframe. For example if article \"2\" is clicked in article_ids_inview entry (1,2,3,4), then the generated binary column, labels, will be (0,1,0,0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>impression_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>impression_time</th>\n",
       "      <th>read_time</th>\n",
       "      <th>scroll_percentage</th>\n",
       "      <th>device_type</th>\n",
       "      <th>article_ids_inview</th>\n",
       "      <th>article_ids_clicked</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_sso_user</th>\n",
       "      <th>...</th>\n",
       "      <th>is_subscriber</th>\n",
       "      <th>session_id</th>\n",
       "      <th>next_read_time</th>\n",
       "      <th>next_scroll_percentage</th>\n",
       "      <th>impression_time_fixed</th>\n",
       "      <th>scroll_percentage_fixed</th>\n",
       "      <th>article_id_fixed</th>\n",
       "      <th>read_time_fixed</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>578909</th>\n",
       "      <td>182440184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-28 09:02:31</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>[9784044, 9784679, 9784058, 9142564, 9782809, ...</td>\n",
       "      <td>[9784591]</td>\n",
       "      <td>437088</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1626986</td>\n",
       "      <td>84.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[2023-05-20T21:32:46.000000, 2023-05-20T21:32:...</td>\n",
       "      <td>[36.0, 100.0, 20.0, 100.0, 100.0, 100.0, 100.0...</td>\n",
       "      <td>[9774079, 9774074, 9772453, 9774120, 9773638, ...</td>\n",
       "      <td>[6.0, 39.0, 7.0, 39.0, 71.0, 8.0, 99.0, 16.0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200232</th>\n",
       "      <td>263268931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-22 05:21:33</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[9754160, 9775430, 9774595, 9775402, 7460419, ...</td>\n",
       "      <td>[9775402]</td>\n",
       "      <td>1327305</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1519807</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>[2023-05-08T05:34:30.000000, 2023-05-10T07:40:...</td>\n",
       "      <td>[16.0, 48.0, 26.0, 52.0, 100.0, 100.0, 100.0, ...</td>\n",
       "      <td>[9753521, 9757183, 9759154, 9759355, 9759418, ...</td>\n",
       "      <td>[3.0, 8.0, 6.0, 22.0, 32.0, 95.0, 7.0, 87.0, 3...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194891</th>\n",
       "      <td>258249876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-21 15:40:24</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[9774598, 9770028, 9774404, 9774708, 9746360, ...</td>\n",
       "      <td>[9774015]</td>\n",
       "      <td>720141</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>375748</td>\n",
       "      <td>28.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>[2023-05-04T06:50:57.000000, 2023-05-04T06:51:...</td>\n",
       "      <td>[56.0, 13.0, 26.0, 70.0, 28.0, 25.0, nan, 26.0...</td>\n",
       "      <td>[9748977, 9745484, 9747490, 9748918, 9748942, ...</td>\n",
       "      <td>[20.0, 27.0, 8.0, 8.0, 12.0, 20.0, 22.0, 17.0,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503093</th>\n",
       "      <td>87132561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-26 17:42:02</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[9782616, 9780651, 9783043, 9782495, 9783056, ...</td>\n",
       "      <td>[9783043]</td>\n",
       "      <td>1447383</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1162569</td>\n",
       "      <td>21.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>[2023-04-27T12:47:48.000000, 2023-04-27T12:48:...</td>\n",
       "      <td>[21.0, 1.0, 70.0, 100.0, 83.0, 79.0, 100.0, 19...</td>\n",
       "      <td>[9733845, 9733713, 9738684, 9738533, 9737521, ...</td>\n",
       "      <td>[21.0, 9.0, 32.0, 115.0, 101.0, 16.0, 22.0, 13...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858950</th>\n",
       "      <td>547070818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-29 05:00:09</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>[9785992, 9785835, 9786111, 9785017, 9785986, ...</td>\n",
       "      <td>[9786111]</td>\n",
       "      <td>885672</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1375847</td>\n",
       "      <td>87.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[2023-04-27T07:30:17.000000, 2023-04-27T09:37:...</td>\n",
       "      <td>[100.0, 94.0, nan, 23.0, 69.0, 15.0, 47.0, 13....</td>\n",
       "      <td>[9738334, 9738569, 9738364, 9738490, 9738760, ...</td>\n",
       "      <td>[1.0, 22.0, 3.0, 4.0, 1276.0, 2.0, 10.0, 4.0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        impression_id  article_id     impression_time  read_time  \\\n",
       "578909      182440184         NaN 2023-05-28 09:02:31        7.0   \n",
       "200232      263268931         NaN 2023-05-22 05:21:33       19.0   \n",
       "194891      258249876         NaN 2023-05-21 15:40:24       46.0   \n",
       "503093       87132561         NaN 2023-05-26 17:42:02       25.0   \n",
       "858950      547070818         NaN 2023-05-29 05:00:09        8.0   \n",
       "\n",
       "        scroll_percentage  device_type  \\\n",
       "578909                NaN            2   \n",
       "200232                NaN            1   \n",
       "194891                NaN            1   \n",
       "503093                NaN            1   \n",
       "858950                NaN            2   \n",
       "\n",
       "                                       article_ids_inview article_ids_clicked  \\\n",
       "578909  [9784044, 9784679, 9784058, 9142564, 9782809, ...           [9784591]   \n",
       "200232  [9754160, 9775430, 9774595, 9775402, 7460419, ...           [9775402]   \n",
       "194891  [9774598, 9770028, 9774404, 9774708, 9746360, ...           [9774015]   \n",
       "503093  [9782616, 9780651, 9783043, 9782495, 9783056, ...           [9783043]   \n",
       "858950  [9785992, 9785835, 9786111, 9785017, 9785986, ...           [9786111]   \n",
       "\n",
       "        user_id  is_sso_user  ...  is_subscriber  session_id  next_read_time  \\\n",
       "578909   437088        False  ...          False     1626986            84.0   \n",
       "200232  1327305        False  ...          False     1519807             4.0   \n",
       "194891   720141        False  ...          False      375748            28.0   \n",
       "503093  1447383        False  ...          False     1162569            21.0   \n",
       "858950   885672        False  ...          False     1375847            87.0   \n",
       "\n",
       "        next_scroll_percentage  \\\n",
       "578909                   100.0   \n",
       "200232                    17.0   \n",
       "194891                    40.0   \n",
       "503093                    37.0   \n",
       "858950                   100.0   \n",
       "\n",
       "                                    impression_time_fixed  \\\n",
       "578909  [2023-05-20T21:32:46.000000, 2023-05-20T21:32:...   \n",
       "200232  [2023-05-08T05:34:30.000000, 2023-05-10T07:40:...   \n",
       "194891  [2023-05-04T06:50:57.000000, 2023-05-04T06:51:...   \n",
       "503093  [2023-04-27T12:47:48.000000, 2023-04-27T12:48:...   \n",
       "858950  [2023-04-27T07:30:17.000000, 2023-04-27T09:37:...   \n",
       "\n",
       "                                  scroll_percentage_fixed  \\\n",
       "578909  [36.0, 100.0, 20.0, 100.0, 100.0, 100.0, 100.0...   \n",
       "200232  [16.0, 48.0, 26.0, 52.0, 100.0, 100.0, 100.0, ...   \n",
       "194891  [56.0, 13.0, 26.0, 70.0, 28.0, 25.0, nan, 26.0...   \n",
       "503093  [21.0, 1.0, 70.0, 100.0, 83.0, 79.0, 100.0, 19...   \n",
       "858950  [100.0, 94.0, nan, 23.0, 69.0, 15.0, 47.0, 13....   \n",
       "\n",
       "                                         article_id_fixed  \\\n",
       "578909  [9774079, 9774074, 9772453, 9774120, 9773638, ...   \n",
       "200232  [9753521, 9757183, 9759154, 9759355, 9759418, ...   \n",
       "194891  [9748977, 9745484, 9747490, 9748918, 9748942, ...   \n",
       "503093  [9733845, 9733713, 9738684, 9738533, 9737521, ...   \n",
       "858950  [9738334, 9738569, 9738364, 9738490, 9738760, ...   \n",
       "\n",
       "                                          read_time_fixed  \\\n",
       "578909  [6.0, 39.0, 7.0, 39.0, 71.0, 8.0, 99.0, 16.0, ...   \n",
       "200232  [3.0, 8.0, 6.0, 22.0, 32.0, 95.0, 7.0, 87.0, 3...   \n",
       "194891  [20.0, 27.0, 8.0, 8.0, 12.0, 20.0, 22.0, 17.0,...   \n",
       "503093  [21.0, 9.0, 32.0, 115.0, 101.0, 16.0, 22.0, 13...   \n",
       "858950  [1.0, 22.0, 3.0, 4.0, 1276.0, 2.0, 10.0, 4.0, ...   \n",
       "\n",
       "                                                   labels labels_len  \n",
       "578909                     [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]         10  \n",
       "200232                              [0, 0, 0, 1, 0, 0, 0]          7  \n",
       "194891  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...         32  \n",
       "503093                              [0, 0, 1, 0, 0, 0, 0]          7  \n",
       "858950                                 [0, 0, 1, 0, 0, 0]          6  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to create binary labels column\n",
    "def create_binary_labels_column(df):\n",
    "    # Define the column names\n",
    "    clicked_col = \"article_ids_clicked\"\n",
    "    inview_col = \"article_ids_inview\"\n",
    "    labels_col = \"labels\"\n",
    "\n",
    "    # Create a new column with binary labels\n",
    "    df[labels_col] = df.apply(lambda row: [1 if article_id in row[clicked_col] else 0 for article_id in row[inview_col]], axis=1)\n",
    "\n",
    "    # Shuffle the data\n",
    "    df = df.sample(frac=1, random_state=123)\n",
    "\n",
    "    # Add a column with the length of the labels list\n",
    "    df[labels_col + \"_len\"] = df[labels_col].apply(len)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the function to your merged dataset\n",
    "behaviour_history_merged = create_binary_labels_column(behaviour_history_merged)\n",
    "\n",
    "# Display the updated dataset\n",
    "behaviour_history_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We average a user's sentiment scores and append it to the dataframe. We do this by iterating through their clicked articles' sentiment scores, and calculating the average.\n",
    "\n",
    "**IMPORTANT:** Sentiment is not correctly implemented. The value is most likely a single value from a vector (negative score, neutral score, positive score), where vector values add up to 1. If we wanted to fix this, we would add a vector instead, where we add the given value in the appropriate field, and half the value of 1 minus given value between the two other fields. This fix is not implemented because the entire model is replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>impression_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>impression_time</th>\n",
       "      <th>read_time</th>\n",
       "      <th>scroll_percentage</th>\n",
       "      <th>device_type</th>\n",
       "      <th>article_ids_inview</th>\n",
       "      <th>article_ids_clicked</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_sso_user</th>\n",
       "      <th>...</th>\n",
       "      <th>session_id</th>\n",
       "      <th>next_read_time</th>\n",
       "      <th>next_scroll_percentage</th>\n",
       "      <th>impression_time_fixed</th>\n",
       "      <th>scroll_percentage_fixed</th>\n",
       "      <th>article_id_fixed</th>\n",
       "      <th>read_time_fixed</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_len</th>\n",
       "      <th>average_sentiment_score_for_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>578909</th>\n",
       "      <td>182440184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-28 09:02:31</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>[9784044, 9784679, 9784058, 9142564, 9782809, ...</td>\n",
       "      <td>[9784591]</td>\n",
       "      <td>437088</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1626986</td>\n",
       "      <td>84.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[2023-05-20T21:32:46.000000, 2023-05-20T21:32:...</td>\n",
       "      <td>[36.0, 100.0, 20.0, 100.0, 100.0, 100.0, 100.0...</td>\n",
       "      <td>[9774079, 9774074, 9772453, 9774120, 9773638, ...</td>\n",
       "      <td>[6.0, 39.0, 7.0, 39.0, 71.0, 8.0, 99.0, 16.0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>10</td>\n",
       "      <td>0.811352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200232</th>\n",
       "      <td>263268931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-22 05:21:33</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[9754160, 9775430, 9774595, 9775402, 7460419, ...</td>\n",
       "      <td>[9775402]</td>\n",
       "      <td>1327305</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1519807</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>[2023-05-08T05:34:30.000000, 2023-05-10T07:40:...</td>\n",
       "      <td>[16.0, 48.0, 26.0, 52.0, 100.0, 100.0, 100.0, ...</td>\n",
       "      <td>[9753521, 9757183, 9759154, 9759355, 9759418, ...</td>\n",
       "      <td>[3.0, 8.0, 6.0, 22.0, 32.0, 95.0, 7.0, 87.0, 3...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>7</td>\n",
       "      <td>0.863900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194891</th>\n",
       "      <td>258249876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-21 15:40:24</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[9774598, 9770028, 9774404, 9774708, 9746360, ...</td>\n",
       "      <td>[9774015]</td>\n",
       "      <td>720141</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>375748</td>\n",
       "      <td>28.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>[2023-05-04T06:50:57.000000, 2023-05-04T06:51:...</td>\n",
       "      <td>[56.0, 13.0, 26.0, 70.0, 28.0, 25.0, nan, 26.0...</td>\n",
       "      <td>[9748977, 9745484, 9747490, 9748918, 9748942, ...</td>\n",
       "      <td>[20.0, 27.0, 8.0, 8.0, 12.0, 20.0, 22.0, 17.0,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.853615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503093</th>\n",
       "      <td>87132561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-26 17:42:02</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[9782616, 9780651, 9783043, 9782495, 9783056, ...</td>\n",
       "      <td>[9783043]</td>\n",
       "      <td>1447383</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1162569</td>\n",
       "      <td>21.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>[2023-04-27T12:47:48.000000, 2023-04-27T12:48:...</td>\n",
       "      <td>[21.0, 1.0, 70.0, 100.0, 83.0, 79.0, 100.0, 19...</td>\n",
       "      <td>[9733845, 9733713, 9738684, 9738533, 9737521, ...</td>\n",
       "      <td>[21.0, 9.0, 32.0, 115.0, 101.0, 16.0, 22.0, 13...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>7</td>\n",
       "      <td>0.863627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858950</th>\n",
       "      <td>547070818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-29 05:00:09</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>[9785992, 9785835, 9786111, 9785017, 9785986, ...</td>\n",
       "      <td>[9786111]</td>\n",
       "      <td>885672</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1375847</td>\n",
       "      <td>87.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[2023-04-27T07:30:17.000000, 2023-04-27T09:37:...</td>\n",
       "      <td>[100.0, 94.0, nan, 23.0, 69.0, 15.0, 47.0, 13....</td>\n",
       "      <td>[9738334, 9738569, 9738364, 9738490, 9738760, ...</td>\n",
       "      <td>[1.0, 22.0, 3.0, 4.0, 1276.0, 2.0, 10.0, 4.0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>6</td>\n",
       "      <td>0.864199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        impression_id  article_id     impression_time  read_time  \\\n",
       "578909      182440184         NaN 2023-05-28 09:02:31        7.0   \n",
       "200232      263268931         NaN 2023-05-22 05:21:33       19.0   \n",
       "194891      258249876         NaN 2023-05-21 15:40:24       46.0   \n",
       "503093       87132561         NaN 2023-05-26 17:42:02       25.0   \n",
       "858950      547070818         NaN 2023-05-29 05:00:09        8.0   \n",
       "\n",
       "        scroll_percentage  device_type  \\\n",
       "578909                NaN            2   \n",
       "200232                NaN            1   \n",
       "194891                NaN            1   \n",
       "503093                NaN            1   \n",
       "858950                NaN            2   \n",
       "\n",
       "                                       article_ids_inview article_ids_clicked  \\\n",
       "578909  [9784044, 9784679, 9784058, 9142564, 9782809, ...           [9784591]   \n",
       "200232  [9754160, 9775430, 9774595, 9775402, 7460419, ...           [9775402]   \n",
       "194891  [9774598, 9770028, 9774404, 9774708, 9746360, ...           [9774015]   \n",
       "503093  [9782616, 9780651, 9783043, 9782495, 9783056, ...           [9783043]   \n",
       "858950  [9785992, 9785835, 9786111, 9785017, 9785986, ...           [9786111]   \n",
       "\n",
       "        user_id  is_sso_user  ...  session_id  next_read_time  \\\n",
       "578909   437088        False  ...     1626986            84.0   \n",
       "200232  1327305        False  ...     1519807             4.0   \n",
       "194891   720141        False  ...      375748            28.0   \n",
       "503093  1447383        False  ...     1162569            21.0   \n",
       "858950   885672        False  ...     1375847            87.0   \n",
       "\n",
       "        next_scroll_percentage  \\\n",
       "578909                   100.0   \n",
       "200232                    17.0   \n",
       "194891                    40.0   \n",
       "503093                    37.0   \n",
       "858950                   100.0   \n",
       "\n",
       "                                    impression_time_fixed  \\\n",
       "578909  [2023-05-20T21:32:46.000000, 2023-05-20T21:32:...   \n",
       "200232  [2023-05-08T05:34:30.000000, 2023-05-10T07:40:...   \n",
       "194891  [2023-05-04T06:50:57.000000, 2023-05-04T06:51:...   \n",
       "503093  [2023-04-27T12:47:48.000000, 2023-04-27T12:48:...   \n",
       "858950  [2023-04-27T07:30:17.000000, 2023-04-27T09:37:...   \n",
       "\n",
       "                                  scroll_percentage_fixed  \\\n",
       "578909  [36.0, 100.0, 20.0, 100.0, 100.0, 100.0, 100.0...   \n",
       "200232  [16.0, 48.0, 26.0, 52.0, 100.0, 100.0, 100.0, ...   \n",
       "194891  [56.0, 13.0, 26.0, 70.0, 28.0, 25.0, nan, 26.0...   \n",
       "503093  [21.0, 1.0, 70.0, 100.0, 83.0, 79.0, 100.0, 19...   \n",
       "858950  [100.0, 94.0, nan, 23.0, 69.0, 15.0, 47.0, 13....   \n",
       "\n",
       "                                         article_id_fixed  \\\n",
       "578909  [9774079, 9774074, 9772453, 9774120, 9773638, ...   \n",
       "200232  [9753521, 9757183, 9759154, 9759355, 9759418, ...   \n",
       "194891  [9748977, 9745484, 9747490, 9748918, 9748942, ...   \n",
       "503093  [9733845, 9733713, 9738684, 9738533, 9737521, ...   \n",
       "858950  [9738334, 9738569, 9738364, 9738490, 9738760, ...   \n",
       "\n",
       "                                          read_time_fixed  \\\n",
       "578909  [6.0, 39.0, 7.0, 39.0, 71.0, 8.0, 99.0, 16.0, ...   \n",
       "200232  [3.0, 8.0, 6.0, 22.0, 32.0, 95.0, 7.0, 87.0, 3...   \n",
       "194891  [20.0, 27.0, 8.0, 8.0, 12.0, 20.0, 22.0, 17.0,...   \n",
       "503093  [21.0, 9.0, 32.0, 115.0, 101.0, 16.0, 22.0, 13...   \n",
       "858950  [1.0, 22.0, 3.0, 4.0, 1276.0, 2.0, 10.0, 4.0, ...   \n",
       "\n",
       "                                                   labels labels_len  \\\n",
       "578909                     [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]         10   \n",
       "200232                              [0, 0, 0, 1, 0, 0, 0]          7   \n",
       "194891  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...         32   \n",
       "503093                              [0, 0, 1, 0, 0, 0, 0]          7   \n",
       "858950                                 [0, 0, 1, 0, 0, 0]          6   \n",
       "\n",
       "       average_sentiment_score_for_user  \n",
       "578909                         0.811352  \n",
       "200232                         0.863900  \n",
       "194891                         0.853615  \n",
       "503093                         0.863627  \n",
       "858950                         0.864199  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary mapping article IDs to sentiment scores\n",
    "sentiment_dict = dict(zip(news['article_id'], news['sentiment_score']))\n",
    "\n",
    "# Function to map sentiment score based on article ID\n",
    "def map_sentiment(article_ids):\n",
    "    # Filter out NaN values and get sentiment scores for clicked articles\n",
    "    sentiment_scores = [sentiment_dict.get(article_id, np.nan) for article_id in article_ids if not pd.isnull(article_id)]\n",
    "    # Calculate the average sentiment score if there are sentiment scores available\n",
    "    if sentiment_scores:\n",
    "        return np.mean(sentiment_scores)\n",
    "    else:\n",
    "        print(\"Error: Unable to calculate average sentiment score. No sentiment scores available for clicked articles.\")\n",
    "        return np.nan\n",
    "\n",
    "# Apply the function to create a new column with average sentiment score\n",
    "behaviour_history_merged['average_sentiment_score_for_user'] = behaviour_history_merged['article_id_fixed'].apply(map_sentiment)\n",
    "\n",
    "# Display the updated dataframe\n",
    "behaviour_history_merged.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For later ease of use, we generate indices for users and articles. Note that the correctness of this is checked later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 20738 unique articles in the dataset\n",
      "We have 18827 unique users in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Build index of items    \n",
    "ind2article = {idx + 1: itemid for idx, itemid in enumerate(news['article_id'].values)}\n",
    "article2ind = {itemid: idx for idx, itemid in ind2article.items()}\n",
    "\n",
    "# Build index of users\n",
    "unique_userIds = behaviour_history_merged['user_id'].unique()\n",
    "ind2user = {idx + 1: itemid for idx, itemid in enumerate(unique_userIds)}\n",
    "user2ind = {itemid: idx for idx, itemid in ind2user.items()}\n",
    "\n",
    "behaviour_history_merged['userIdx'] = behaviour_history_merged['user_id'].map(lambda x: user2ind.get(x, 0))\n",
    "behaviour_history_merged['articleIdx'] = behaviour_history_merged['article_id'].map(lambda x: article2ind.get(x, 0))\n",
    "print(f\"We have {len(article2ind)} unique articles in the dataset\")\n",
    "print(f\"We have {len(user2ind)} unique users in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split our data into train and validation sets. We will use the train set to train our model and the validation set to evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and validation\n",
    "test_time_threshold = behaviour_history_merged['impression_time'].quantile(0.9)\n",
    "train_data = behaviour_history_merged[behaviour_history_merged['impression_time'] < test_time_threshold]\n",
    "valid_data = behaviour_history_merged[behaviour_history_merged['impression_time'] >= test_time_threshold]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the dataset model. This is used in the machine learning model itself later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EBNeRDMindDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.data = {\n",
    "            'userIdx': torch.tensor(df.userIdx.values),\n",
    "            'articleIdx': torch.tensor(df.articleIdx.values),\n",
    "            'labels': torch.tensor([item for sublist in df.labels for item in sublist], dtype=torch.float32),\n",
    "            'sentiment_score': torch.tensor(df.average_sentiment_score_for_user.values, dtype=torch.float32),\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data['userIdx'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'userIdx': self.data['userIdx'][idx],\n",
    "            'articleIdx': self.data['articleIdx'][idx],\n",
    "            'click': self.data['labels'][idx].long(),\n",
    "            'noclick': 1 - self.data['labels'][idx].long(),\n",
    "            'sentiment_score': self.data['sentiment_score'][idx],\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define datasets and dataloaders that will be used in the machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build datasets and dataloaders for train and validation dataframes\n",
    "bs = 1024\n",
    "ds_train = EBNeRDMindDataset(train_data)\n",
    "train_loader = DataLoader(ds_train, batch_size=bs, shuffle=True)\n",
    "ds_valid = EBNeRDMindDataset(valid_data)\n",
    "valid_loader = DataLoader(ds_valid, batch_size=bs, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section defines our neural network model. It includes creating data loaders, defining the model architecture (NewsMF), specifying training steps, validation steps, optimizer, and training configurations. Note that this is only the first model, which is more messy, and not as well performing as the second model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics.classification import BinaryF1Score, BinaryAUROC\n",
    "\n",
    "class NewsMF(pl.LightningModule):\n",
    "    def __init__(self, num_users, num_items, dim=10):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.useremb = nn.Embedding(num_embeddings=num_users, embedding_dim=dim)\n",
    "        self.itememb = nn.Embedding(num_embeddings=num_items, embedding_dim=dim)\n",
    "\n",
    "        # BinaryF1Score metric\n",
    "        self.f1_metric = BinaryF1Score()\n",
    "        self.train_step_f1_outputs = []\n",
    "        self.validation_step_f1_outputs = []\n",
    "\n",
    "        # BinaryAUROC metric\n",
    "        self.binary_auroc = BinaryAUROC()\n",
    "        self.train_step_auroc_outputs = []\n",
    "        self.validation_step_auroc_outputs = []\n",
    "\n",
    "    def forward(self, user, item, sentiment):\n",
    "        batch_size = user.size(0)\n",
    "        uservec = self.useremb(user)\n",
    "        itemvec = self.itememb(item)\n",
    "        \n",
    "        # Concatenate user and item embeddings with sentiment scores\n",
    "        uservec = torch.cat((uservec, sentiment.unsqueeze(-1)), dim=1)\n",
    "        itemvec = torch.cat((itemvec, sentiment.unsqueeze(-1)), dim=1)\n",
    "\n",
    "        score = (uservec * itemvec).sum(-1).unsqueeze(-1)\n",
    "\n",
    "        return score\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        batch_size = batch['userIdx'].size(0)\n",
    "\n",
    "        score_click = self.forward(batch['userIdx'], batch['click'], batch['sentiment_score'])\n",
    "        score_noclick = self.forward(batch['userIdx'], batch['noclick'], batch['sentiment_score'])\n",
    "\n",
    "        loss = F.cross_entropy(input=torch.cat((score_click, score_noclick), dim=1),\n",
    "                               target=torch.zeros(batch_size, device=score_click.device).long())\n",
    "\n",
    "        # Compute F1-score\n",
    "        f1_click = self.f1_metric(score_click.squeeze(), torch.ones_like(batch['click']))\n",
    "        f1_noclick = self.f1_metric(score_noclick.squeeze(), torch.zeros_like(batch['noclick']))\n",
    "\n",
    "        # Average F1-scores\n",
    "        f1 = (f1_click + f1_noclick) / 2.0\n",
    "\n",
    "        self.train_step_f1_outputs.append(f1)\n",
    "\n",
    "        # Calculate Binary AUROC\n",
    "        binary_auroc_score = self.binary_auroc(torch.cat((score_click, score_noclick), dim=1),\n",
    "                                                torch.cat((torch.ones_like(batch['click']),\n",
    "                                                           torch.zeros_like(batch['noclick'])))\n",
    "                                               )\n",
    "        \n",
    "        self.train_step_auroc_outputs.append(binary_auroc_score)\n",
    "\n",
    "        return {'loss': loss, 'f1': f1, 'auroc': binary_auroc_score}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        score_click = self.forward(batch['userIdx'], batch['click'], batch['sentiment_score'])\n",
    "        score_noclick = self.forward(batch['userIdx'], batch['noclick'], batch['sentiment_score'])\n",
    "\n",
    "        loss = F.cross_entropy(input=torch.cat((score_click, score_noclick), dim=1),\n",
    "                            target=torch.zeros(batch['userIdx'].size(0), device=score_click.device).long())\n",
    "\n",
    "        # F1 Score\n",
    "        f1_click = self.f1_metric(score_click.squeeze(), torch.ones_like(batch['click']))\n",
    "        f1_noclick = self.f1_metric(score_noclick.squeeze(), torch.zeros_like(batch['noclick']))\n",
    "        f1 = (f1_click + f1_noclick) / 2.0 # Average F1-scores\n",
    "\n",
    "        self.validation_step_f1_outputs.append(f1)\n",
    "\n",
    "        # Calculate Binary AUROC\n",
    "        binary_auroc_score = self.binary_auroc(torch.cat((score_click, score_noclick), dim=1),\n",
    "                                                torch.cat((torch.ones_like(batch['click']),\n",
    "                                                           torch.zeros_like(batch['noclick'])))\n",
    "                                               )\n",
    "        \n",
    "        self.validation_step_auroc_outputs.append(binary_auroc_score)\n",
    "                \n",
    "        return {'loss': loss, 'f1': f1, 'auroc': binary_auroc_score}\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        epoch_average_f1 = torch.stack(self.train_step_f1_outputs).mean()\n",
    "        print(f'Epoch {self.current_epoch}: Training F1 Score: {epoch_average_f1.item()}')\n",
    "        self.log(\"train_epoch_average_f1\", epoch_average_f1)\n",
    "        self.train_step_f1_outputs.clear()  # free memory\n",
    "\n",
    "        epoch_average_auroc = torch.stack(self.train_step_auroc_outputs).mean()\n",
    "        print(f'Epoch {self.current_epoch}: Training AUROC Score: {epoch_average_auroc.item()}')\n",
    "        self.log(\"train_epoch_average_auroc\", epoch_average_auroc)\n",
    "        self.validation_step_auroc_outputs.clear()  # free memory\n",
    "\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        epoch_average_f1 = torch.stack(self.validation_step_f1_outputs).mean()\n",
    "        print(f'Epoch {self.current_epoch}: Validation F1 Score: {epoch_average_f1.item()}')\n",
    "        self.log(\"validation_epoch_average_f1\", epoch_average_f1)\n",
    "        self.validation_step_f1_outputs.clear()  # free memory\n",
    "\n",
    "        epoch_average_auroc = torch.stack(self.validation_step_auroc_outputs).mean()\n",
    "        print(f'Epoch {self.current_epoch}: Validation AUROC Score: {epoch_average_auroc.item()}')\n",
    "        self.log(\"validation_epoch_average_auroc\", epoch_average_auroc)\n",
    "        self.validation_step_auroc_outputs.clear()  # free memory\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate the model, the trainer, and run the trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params\n",
      "-----------------------------------------------\n",
      "0 | useremb      | Embedding     | 188 K \n",
      "1 | itememb      | Embedding     | 207 K \n",
      "2 | f1_metric    | BinaryF1Score | 0     \n",
      "3 | binary_auroc | BinaryAUROC   | 0     \n",
      "-----------------------------------------------\n",
      "395 K     Trainable params\n",
      "0         Non-trainable params\n",
      "395 K     Total params\n",
      "1.583     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d817518b6b0341a8ba1ed278415e8888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Validation F1 Score: 0.3668864369392395\n",
      "Epoch 0: Validation AUROC Score: 0.47754335403442383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc98a6f694e44e5abee7753dd3b6fb6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "741e71949d834d958a5ecc2b1433904c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Validation F1 Score: 0.39982688426971436\n",
      "Epoch 0: Validation AUROC Score: 0.49833253026008606\n",
      "Epoch 0: Training F1 Score: 0.38376784324645996\n",
      "Epoch 0: Training AUROC Score: 0.5002530217170715\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9cc8cba8f2d4fc9ab0f3effe4df0cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Validation F1 Score: 0.41821375489234924\n",
      "Epoch 1: Validation AUROC Score: 0.49845242500305176\n",
      "Epoch 1: Training F1 Score: 0.40993988513946533\n",
      "Epoch 1: Training AUROC Score: 0.4999447166919708\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06874ca9354342648c1ad778c27ab18c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Validation F1 Score: 0.4263119399547577\n",
      "Epoch 2: Validation AUROC Score: 0.498483806848526\n",
      "Epoch 2: Training F1 Score: 0.42293581366539\n",
      "Epoch 2: Training AUROC Score: 0.4995303452014923\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6593fc1b99794bb58505e86257d559cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Validation F1 Score: 0.43029481172561646\n",
      "Epoch 3: Validation AUROC Score: 0.49846577644348145\n",
      "Epoch 3: Training F1 Score: 0.4295817017555237\n",
      "Epoch 3: Training AUROC Score: 0.49956706166267395\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c92d1f6c4e424fbd023e3008a3a15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Validation F1 Score: 0.432224839925766\n",
      "Epoch 4: Validation AUROC Score: 0.49845150113105774\n",
      "Epoch 4: Training F1 Score: 0.4323936104774475\n",
      "Epoch 4: Training AUROC Score: 0.49963217973709106\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e049ee8154204b229d76a22029ca5d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Validation F1 Score: 0.43374064564704895\n",
      "Epoch 5: Validation AUROC Score: 0.4984639883041382\n",
      "Epoch 5: Training F1 Score: 0.4337572157382965\n",
      "Epoch 5: Training AUROC Score: 0.49976715445518494\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc25cb82a83041f6b12c02936f50ba65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Validation F1 Score: 0.4341133236885071\n",
      "Epoch 6: Validation AUROC Score: 0.49846339225769043\n",
      "Epoch 6: Training F1 Score: 0.43463417887687683\n",
      "Epoch 6: Training AUROC Score: 0.499746173620224\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b2ce15b3a143e0a13e3e548be1662e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Validation F1 Score: 0.4347049593925476\n",
      "Epoch 7: Validation AUROC Score: 0.4984622299671173\n",
      "Epoch 7: Training F1 Score: 0.43513062596321106\n",
      "Epoch 7: Training AUROC Score: 0.4997369050979614\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429bb75ff13d46e99566c5f6aeafea6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Validation F1 Score: 0.4347802996635437\n",
      "Epoch 8: Validation AUROC Score: 0.4984569847583771\n",
      "Epoch 8: Training F1 Score: 0.4353675842285156\n",
      "Epoch 8: Training AUROC Score: 0.499746173620224\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "982c13435ff04fbbb8174d143f9e16ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Validation F1 Score: 0.4350593090057373\n",
      "Epoch 9: Validation AUROC Score: 0.4984586834907532\n",
      "Epoch 9: Training F1 Score: 0.4356866478919983\n",
      "Epoch 9: Training AUROC Score: 0.4997742474079132\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "ebnerd_model = NewsMF(num_users=len(user2ind) + 1, num_items=len(article2ind) + 1)\n",
    "\n",
    "# Instantiate the trainer\n",
    "trainer = pl.Trainer(max_epochs=10, logger=logger)\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model=ebnerd_model, train_dataloaders=train_loader, val_dataloaders=valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print the logs (F1 score and AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validation logs: {'validation_epoch_average_f1': tensor(0.4351), 'validation_epoch_average_auroc': tensor(0.4985), 'train_epoch_average_f1': tensor(0.4357), 'train_epoch_average_auroc': tensor(0.4998)}\n"
     ]
    }
   ],
   "source": [
    "# Print the logs\n",
    "logs = trainer.logged_metrics\n",
    "print(\"Training and validation logs:\", logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our second model, written in a different approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define the dataset model, it is pretty much identical to the one above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EBNeRDMindDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.data = {\n",
    "            'userIdx': torch.tensor(df.userIdx.values),\n",
    "            'articleIdx': torch.tensor(df.articleIdx.values),\n",
    "            'click': torch.tensor([item for sublist in df.labels for item in sublist], dtype=torch.float32),\n",
    "            'noclick': 1 - torch.tensor([item for sublist in df.labels for item in sublist], dtype=torch.float32),\n",
    "            'sentiment_score': torch.tensor(df.average_sentiment_score_for_user.values, dtype=torch.float32),\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data['userIdx'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'userIdx': self.data['userIdx'][idx],\n",
    "            'articleIdx': self.data['articleIdx'][idx],\n",
    "            'click': self.data['click'][idx].long(),\n",
    "            'noclick': self.data['noclick'][idx].long(),\n",
    "            'sentiment_score': self.data['sentiment_score'][idx],\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the model itself. Note that the F1 score is broken at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "class RecommenderModel(pl.LightningModule):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=64):\n",
    "        super().__init__()\n",
    "        self.user_embeddings = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embeddings = nn.Embedding(num_items, embedding_dim)\n",
    "        self.fc1 = nn.Linear(embedding_dim * 2, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, user_idx, item_idx, sentiment_score):\n",
    "        user_embedding = self.user_embeddings(user_idx)\n",
    "        item_embedding = self.item_embeddings(item_idx)\n",
    "        x = torch.cat([user_embedding, item_embedding], dim=1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        user_idx = batch['userIdx']\n",
    "        item_idx = batch['articleIdx']\n",
    "        sentiment_score = batch['sentiment_score']\n",
    "        click = batch['click']\n",
    "        output = self(user_idx, item_idx, sentiment_score).squeeze()\n",
    "\n",
    "        # Calculate Loss\n",
    "        loss = F.binary_cross_entropy_with_logits(output, click.float())  # Convert click to float\n",
    "\n",
    "        # Calculate AUC-ROC\n",
    "        predicted_probs = torch.sigmoid(output)\n",
    "        auc_roc = roc_auc_score(click.cpu().numpy(), predicted_probs.cpu().detach().numpy())\n",
    "\n",
    "        # Calculate F1 score\n",
    "        predicted_labels = predicted_probs > 0.5\n",
    "        f1 = f1_score(click.cpu().numpy(), predicted_labels.cpu().numpy())\n",
    "\n",
    "        # Log\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        self.log('train_auc_roc', auc_roc, prog_bar=True)  # Log AUC-ROC score\n",
    "        self.log('train_f1_score', f1, prog_bar=True)  # Log F1 score\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        user_idx = batch['userIdx']\n",
    "        item_idx = batch['articleIdx']\n",
    "        sentiment_score = batch['sentiment_score']\n",
    "        click = batch['click']\n",
    "        output = self(user_idx, item_idx, sentiment_score).squeeze()\n",
    "        loss = F.binary_cross_entropy_with_logits(output, click.float())  # Convert click to float\n",
    "\n",
    "        # Calculate AUC-ROC\n",
    "        predicted_probs = torch.sigmoid(output)\n",
    "        auc_roc = roc_auc_score(click.cpu().numpy(), predicted_probs.cpu().detach().numpy())\n",
    "\n",
    "        # Calculate F1 score\n",
    "        predicted_labels = predicted_probs > 0.5\n",
    "        f1 = f1_score(click.cpu().numpy(), predicted_labels.cpu().numpy())\n",
    "\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_auc_roc', auc_roc, prog_bar=True)  # Log AUC-ROC score\n",
    "        self.log('val_f1_score', f1, prog_bar=True)  # Log F1 score\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate the model and trainer, then run the trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "d:\\Anaconda\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:653: Checkpoint directory tb_logs\\my_model\\version_29\\checkpoints exists and is not empty.\n",
      "\n",
      "  | Name            | Type      | Params\n",
      "----------------------------------------------\n",
      "0 | user_embeddings | Embedding | 1.2 M \n",
      "1 | item_embeddings | Embedding | 1.3 M \n",
      "2 | fc1             | Linear    | 16.5 K\n",
      "3 | fc2             | Linear    | 8.3 K \n",
      "4 | fc3             | Linear    | 65    \n",
      "----------------------------------------------\n",
      "2.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.6 M     Total params\n",
      "10.228    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c917d2ed9c64f6e8b1929fd2ad4e132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa1c21805b34a17b89879828dbc366d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c722e0488e143eaa648a7e505f17347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92d9552ab5c482a88abacca58841a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61575e642ee04cfb9f2ecbf796f238dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01919905de624916a80be565995ad80b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc5611cddea433ab1af763c86d8dc9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac823ebd908450db0623d4aa77e33cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f280920180294b27bde7996ea1e2eae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef9fa4df8634053a4758a1612768b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59229ae63b704d51884344aec568863c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "949235274f394c12871fe6b35013e6a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "model = RecommenderModel(num_users=len(user2ind) + 1, num_items=len(article2ind) + 1)\n",
    "trainer = pl.Trainer(logger=logger, max_epochs=10)\n",
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F1 and AUC scores are logged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validation logs: {'train_loss': tensor(0.2622), 'train_auc_roc': tensor(0.6321), 'train_f1_score': tensor(0.), 'val_loss': tensor(0.3081), 'val_auc_roc': tensor(0.4984), 'val_f1_score': tensor(0.0018)}\n"
     ]
    }
   ],
   "source": [
    "# Print the logs\n",
    "logs = trainer.logged_metrics\n",
    "print(\"Training and validation logs:\", logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction test for Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we perform a prediction test using our trained model. It involves selecting a random user, generating predictions for item recommendations, and filtering the top recommended items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "NewsMF.forward() missing 1 required positional argument: 'sentiment'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m item_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ind2article\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m      4\u001b[0m userIdx \u001b[38;5;241m=\u001b[39m  [USER_ID]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(item_id)\n\u001b[1;32m----> 6\u001b[0m preditions \u001b[38;5;241m=\u001b[39m ebnerd_model\u001b[38;5;241m.\u001b[39mforward(torch\u001b[38;5;241m.\u001b[39mIntTensor(userIdx), torch\u001b[38;5;241m.\u001b[39mIntTensor(item_id))\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Select top 10 argmax\u001b[39;00m\n\u001b[0;32m      9\u001b[0m top_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtopk(preditions\u001b[38;5;241m.\u001b[39mflatten(), \u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mindices\n",
      "\u001b[1;31mTypeError\u001b[0m: NewsMF.forward() missing 1 required positional argument: 'sentiment'"
     ]
    }
   ],
   "source": [
    "USER_ID = 2350 # Random user id\n",
    "# Create item_ids and user ids list\n",
    "item_id = list(ind2article.keys())\n",
    "userIdx =  [USER_ID]*len(item_id)\n",
    "\n",
    "preditions = ebnerd_model.forward(torch.IntTensor(userIdx), torch.IntTensor(item_id))\n",
    "\n",
    "# Select top 10 argmax\n",
    "top_index = torch.topk(preditions.flatten(), 10).indices\n",
    "\n",
    "# Filter for top 10 suggested items\n",
    "filters = [ind2article[ix.item()] for ix in top_index]\n",
    "news[news[\"article_id\"].isin(filters)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section saves the trained model's state dictionary to a specified directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the relative directory path\n",
    "relative_directory = \"Saved_Model/\"\n",
    "\n",
    "# Create the full directory path\n",
    "directory_path = os.path.join(relative_directory)\n",
    "\n",
    "# Create the directory if it does not exist\n",
    "os.makedirs(directory_path, exist_ok=True)\n",
    "\n",
    "# Save the state dictionary of the model to the specified directory\n",
    "model_save_path = os.path.join(directory_path, \"EBNERD_collaborative_filtering_model.pth\")\n",
    "torch.save(ebnerd_model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we load the saved model from the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the state dictionary from the specified directory\n",
    "loaded_model = NewsMF(num_users=len(ind2user)+1, num_items=len(ind2article)+1)\n",
    "\n",
    "# Use a relative path when loading the model\n",
    "model_load_path = os.path.join(\"Saved_Model\", \"EBNERD_collaborative_filtering_model.pth\")\n",
    "loaded_model.load_state_dict(torch.load(model_load_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loaded Model 1 Single Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the prediction test, but this time, it involves loading the saved model and making predictions for a specific user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       article_id                                              title  \\\n",
      "5433      8904651                     Anastasia, 24 år og fra Herlev   \n",
      "7499      9344914                     Kimmie, 29 år og fra København   \n",
      "7608      9358095          Iværksætterskolen: Sådan kommer du i gang   \n",
      "8798      9482881   FN: 150 skibe med korn hober sig op ved Istanbul   \n",
      "10618     9623877  Sigtelse: Rapperen Miklo kom med dødstrusler u...   \n",
      "13762     9728282                       Her er det spiselige batteri   \n",
      "14122     9733519                          Ukraine slår igen på Krim   \n",
      "14412     9735665  Kvist Industries øger omsætningen med et tocif...   \n",
      "18879     9778236                               Brand i større villa   \n",
      "19149     9781264        Sabbatår i udlandet er også for håndværkere   \n",
      "\n",
      "                                                subtitle  last_modified_time  \\\n",
      "5433                                                     2023-06-29 06:38:13   \n",
      "7499                                                     2023-06-29 06:42:39   \n",
      "7608   Det gælder ikke blot om at få den gode idé. Ma... 2023-06-29 06:42:48   \n",
      "8798   Korn i tonsvis fra Ukraine og Rusland når kun ... 2023-06-29 06:44:42   \n",
      "10618  Drill-rapperen Miklo med det borgerlige navn A... 2023-06-29 06:46:46   \n",
      "13762  Forskere håber på, at batteriet vil blive brug... 2023-06-29 06:48:14   \n",
      "14122  Rusland hævder at have afvist et droneangreb p... 2023-06-29 06:48:18   \n",
      "14412  Kvist Industries A/S øger omsætningen med 19 p... 2023-06-29 06:48:19   \n",
      "18879       En større villa er brudt i brand i Haderslev 2023-06-29 06:49:01   \n",
      "19149                                     Lige for alle: 2023-06-29 06:49:04   \n",
      "\n",
      "       premium                                               body  \\\n",
      "5433      True                                                      \n",
      "7499      True                                                      \n",
      "7608      True  Måske har du en alle tiders idé. Du har set hu...   \n",
      "8798     False  Russisk og ukrainsk korn hober sig op i og omk...   \n",
      "10618    False  Den 25-årige rapper Miklo med det borgerlige n...   \n",
      "13762    False  Som udgangspunkt er det en rigtig dårlig idé a...   \n",
      "14122    False  Mens russiske tropper hævder at have fremgang ...   \n",
      "14412    False  Selvom omsætningen sidste år blev større, så e...   \n",
      "18879    False  Syd- og Sønderjyllands Politi er lige nu til s...   \n",
      "19149    False  Det er næsten mere reglen end undtagelsen, at ...   \n",
      "\n",
      "           published_time                    image_ids  \\\n",
      "5433  2021-10-25 21:30:00                    [8904649]   \n",
      "7499  2022-07-29 20:00:00                    [9344913]   \n",
      "7608  2022-09-01 10:03:23           [9358075, 9358074]   \n",
      "8798  2022-10-24 12:44:06                         None   \n",
      "10618 2023-02-06 13:50:43           [9171756, 9171855]   \n",
      "13762 2023-04-24 21:48:06  [9728247, 9728269, 9728268]   \n",
      "14122 2023-04-24 04:54:40                    [9733527]   \n",
      "14412 2023-04-25 13:33:53                    [9735664]   \n",
      "18879 2023-05-23 17:59:05                         None   \n",
      "19149 2023-05-26 13:56:07           [9781250, 9781251]   \n",
      "\n",
      "                 article_type  \\\n",
      "5433   article_page_nine_girl   \n",
      "7499   article_page_nine_girl   \n",
      "7608          article_default   \n",
      "8798          article_default   \n",
      "10618         article_default   \n",
      "13762         article_default   \n",
      "14122         article_default   \n",
      "14412         article_default   \n",
      "18879         article_default   \n",
      "19149         article_default   \n",
      "\n",
      "                                                     url  ...  \\\n",
      "5433     https://ekstrabladet.dk/side9/anastasia/8904651  ...   \n",
      "7499        https://ekstrabladet.dk/side9/kimmie/9344914  ...   \n",
      "7608   https://ekstrabladet.dk/forbrug/goderaadom/iva...  ...   \n",
      "8798   https://ekstrabladet.dk/nyheder/erhverv/fn-150...  ...   \n",
      "10618  https://ekstrabladet.dk/krimi/sigtelse-rappere...  ...   \n",
      "13762  https://ekstrabladet.dk/nyheder/videnskab/her-...  ...   \n",
      "14122  https://ekstrabladet.dk/nyheder/krigogkatastro...  ...   \n",
      "14412  https://ekstrabladet.dk/auto/magna/regnskaber/...  ...   \n",
      "18879  https://ekstrabladet.dk/krimi/brand-i-stoerre-...  ...   \n",
      "19149  https://ekstrabladet.dk/Haandvaerkeren/sabbata...  ...   \n",
      "\n",
      "                                           entity_groups  \\\n",
      "5433                                               [LOC]   \n",
      "7499                                          [LOC, PER]   \n",
      "7608                      [PER, LOC, ORG, PER, LOC, LOC]   \n",
      "8798   [ORG, LOC, PER, PER, LOC, ORG, LOC, LOC, LOC, ...   \n",
      "10618                          [PER, ORG, ORG, LOC, ORG]   \n",
      "13762                                        [ORG, PROD]   \n",
      "14122  [LOC, PER, LOC, ORG, PER, LOC, PER, PER, LOC, ...   \n",
      "14412                          [LOC, ORG, ORG, LOC, LOC]   \n",
      "18879                     [ORG, LOC, LOC, ORG, ORG, LOC]   \n",
      "19149  [PER, LOC, LOC, PER, PER, ORG, LOC, PER, ORG, ...   \n",
      "\n",
      "                                                  topics category  \\\n",
      "5433                           [Kendt, Livsstil, Erotik]      572   \n",
      "7499                                  [Livsstil, Erotik]      572   \n",
      "7608        [Erhverv, Privat virksomhed, Økonomi, Mikro]      457   \n",
      "8798   [Transportmiddel, Politik, International polit...      118   \n",
      "10618   [Kriminalitet, Kendt, Personfarlig kriminalitet]      140   \n",
      "13762             [Teknologi, Videnskab, Naturvidenskab]      118   \n",
      "14122  [Politik, International politik, Konflikt og k...      118   \n",
      "14412              [Erhverv, Privat virksomhed, Økonomi]     2889   \n",
      "18879                 [Katastrofe, Mindre ulykke, Bolig]      140   \n",
      "19149  [Erhverv, Kultur, Rejse, Uddannelse, Ungdomsud...      561   \n",
      "\n",
      "        subcategory    category_str total_inviews  total_pageviews  \\\n",
      "5433             []           side9           NaN              NaN   \n",
      "7499             []           side9           NaN              NaN   \n",
      "7608          [496]         forbrug           NaN              NaN   \n",
      "8798          [123]         nyheder           NaN              NaN   \n",
      "10618            []           krimi           NaN              NaN   \n",
      "13762         [138]         nyheder      252610.0          47592.0   \n",
      "14122         [127]         nyheder      397309.0          92900.0   \n",
      "14412  [2890, 2900]            auto       20566.0             58.0   \n",
      "18879            []           krimi      323441.0          71409.0   \n",
      "19149            []  haandvaerkeren        1146.0              4.0   \n",
      "\n",
      "       total_read_time  sentiment_score  sentiment_label  \n",
      "5433               NaN           0.6071          Neutral  \n",
      "7499               NaN           0.6099          Neutral  \n",
      "7608               NaN           0.6957          Neutral  \n",
      "8798               NaN           0.9706         Negative  \n",
      "10618              NaN           0.9966         Negative  \n",
      "13762        3174669.0           0.6876         Positive  \n",
      "14122        6851242.0           0.9407         Negative  \n",
      "14412           2911.0           0.9750         Positive  \n",
      "18879        2478857.0           0.9940         Negative  \n",
      "19149            635.0           0.9512          Neutral  \n",
      "\n",
      "[10 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Specify the user ID for prediction\n",
    "USER_ID = 1234\n",
    "PREDICTION_COUNT = 10\n",
    "\n",
    "# Create item_ids and user ids list\n",
    "article_id = list(ind2article.keys())\n",
    "userIdx = [USER_ID] * len(article_id)\n",
    "\n",
    "# Convert lists to PyTorch tensors\n",
    "user_tensor = torch.IntTensor(userIdx)\n",
    "item_tensor = torch.IntTensor(article_id)\n",
    "\n",
    "# Forward pass to get predictions\n",
    "predictions = loaded_model.forward(user_tensor, item_tensor)\n",
    "\n",
    "# Select top 10 indices\n",
    "top_indices = torch.topk(predictions.flatten(), PREDICTION_COUNT).indices\n",
    "\n",
    "# Get corresponding item IDs\n",
    "top_item_ids = [ind2article[ix.item()] for ix in top_indices]\n",
    "\n",
    "# Filter for top 10 suggested items\n",
    "recommended_items = news[news[\"article_id\"].isin(top_item_ids)]\n",
    "\n",
    "# Display the recommended items\n",
    "recommended_items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section loads and starts TensorBoard to visualize training metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 27724), started 1:10:08 ago. (Use '!kill 27724' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d72968c130e0864\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d72968c130e0864\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the extension and start TensorBoard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir tb_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section contains various utility functions and commands. It includes converting the notebook to a Python script, getting a random user ID, and validating index mappings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Python Script (not needed right now but keep as utility)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exports the entire notebook as a Python Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook EBNERD_Notebook.ipynb to script\n",
      "[NbConvertApp] Writing 16222 bytes to EBNERD_Notebook.py\n"
     ]
    }
   ],
   "source": [
    "!python -m nbconvert --to script EBNERD_Notebook.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get random user id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gets a random user_id from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected user ID: 2499828\n"
     ]
    }
   ],
   "source": [
    "random_user_index = np.random.randint(0, len(behaviors))\n",
    "random_user_id = behaviors.iloc[random_user_index]['user_id']\n",
    "\n",
    "print(f\"Randomly selected user ID: {random_user_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate conversion consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests user2ind, article2ind, ind2user, and ind2article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected user ID: 591009\n",
      "Randomly selected article ID: 8907869\n",
      "User index: 4882\n",
      "Retrieved user ID: 591009\n",
      "Article index: 5462\n",
      "Retrieved article ID: 8907869\n",
      "User Mapping Consistency: True\n",
      "Article Mapping Consistency: True\n"
     ]
    }
   ],
   "source": [
    "def validate_mapping_consistency(user2ind, ind2user, article2ind, ind2article):\n",
    "    # Choose a random user and article ID for validation\n",
    "    random_user_id = np.random.choice(list(user2ind.keys()))\n",
    "    random_article_id = np.random.choice(list(article2ind.keys()))\n",
    "    print(f\"Randomly selected user ID: {random_user_id}\")\n",
    "    print(f\"Randomly selected article ID: {random_article_id}\")\n",
    "\n",
    "    # Validate user mapping\n",
    "    user_index = user2ind.get(random_user_id)\n",
    "    retrieved_user_id = ind2user.get(user_index)\n",
    "    print(f\"User index: {user_index}\")\n",
    "    print(f\"Retrieved user ID: {retrieved_user_id}\")\n",
    "    \n",
    "    user_mapping_consistent = random_user_id == retrieved_user_id\n",
    "\n",
    "    # Validate article mapping\n",
    "    article_index = article2ind.get(random_article_id)\n",
    "    retrieved_article_id = ind2article.get(article_index)\n",
    "    print(f\"Article index: {article_index}\")\n",
    "    print(f\"Retrieved article ID: {retrieved_article_id}\")\n",
    "\n",
    "    article_mapping_consistent = random_article_id == retrieved_article_id\n",
    "\n",
    "    return user_mapping_consistent, article_mapping_consistent\n",
    "\n",
    "# Perform validation\n",
    "user_consistency, article_consistency = validate_mapping_consistency(user2ind, ind2user, article2ind, ind2article)\n",
    "\n",
    "# Print results\n",
    "print(f\"User Mapping Consistency: {user_consistency}\")\n",
    "print(f\"Article Mapping Consistency: {article_consistency}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
